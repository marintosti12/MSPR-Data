{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 35,
         "metadata": {},
         "outputs": [],
         "source": [
            "import luigi\n",
            "import pandas as pd\n",
            "import os\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Création du dossier pour stocker les données nettoyées"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 36,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dossier créé avec succès.\n"
               ]
            }
         ],
         "source": [
            "# Vérifiez si le dossier n'existe pas déjà\n",
            "\n",
            "dossier = 'CleanData'\n",
            "\n",
            "if not os.path.exists(dossier):\n",
            "    # Créez le dossier\n",
            "    os.makedirs(dossier, mode=0o777)\n",
            "    os.makedirs(os.path.join(dossier, \"2017\"), mode=0o777)\n",
            "    os.makedirs(os.path.join(dossier, \"2022\"), mode=0o777)\n",
            "    print(\"Dossier créé avec succès.\")\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Extraire les données sur la délinquance"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 37,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/communes.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        \n",
            "        # Chargement des dataset\n",
            "        communes = pd.read_csv(self.file_path, sep=\",\", low_memory=False)\n",
            "        df_partis = pd.read_csv('./RawData/Partis.csv', sep=\",\")\n",
            "\n",
            "        # Sélectionner les colonnes nécessaires\n",
            "        colonnes = ['Code du département', 'Libellé du département', 'Code de la commune', 'Libellé de la commune', 'Inscrits', 'Abstentions', '% Abs/Ins', 'Votants', '% Vot/Ins', 'Blancs', '% Blancs/Ins', '% Blancs/Vot', 'Nuls', '% Nuls/Ins', '% Nuls/Vot', 'Exprimés', '% Exp/Ins', '% Exp/Vot']\n",
            "\n",
            "        # Créer un nouveau DataFrame pour les candidats distincts\n",
            "        df_candidats = pd.DataFrame()\n",
            "\n",
            "        # Parcourir les colonnes par groupes de 8 (car chaque candidat occupe 8 colonnes)\n",
            "        for i in range(18, len(communes.columns), 7):\n",
            "            # Sélectionner les colonnes du candidat actuel\n",
            "            colonnes_candidat = communes.columns[i:i+7]\n",
            "\n",
            "            # Renommer les colonnes du candidat\n",
            "            df_candidat = communes[colonnes_candidat].copy()\n",
            "            \n",
            "            df_candidat = pd.DataFrame(df_candidat.values, columns=['N°Panneau','Sexe','Nom','Prenom','Voix','% Voix/Ins','% Voix/Exp'])\n",
            "\n",
            "            # Ajouter les colonnes supplémentaires (Code du département, Libellé du département, etc.)\n",
            "            df_candidat = pd.concat([communes[colonnes], df_candidat], axis=1)            \n",
            "            \n",
            "            # Ajouter les données du candidat au DataFrame des candidats distincts\n",
            "            df_candidats = pd.concat([df_candidats, df_candidat])\n",
            "\n",
            "        df_candidats = pd.merge(df_candidats, df_partis, on=['Nom', 'Prenom'], how='inner')\n",
            "\n",
            "        df_candidats = df_candidats.drop([\"Abstentions\",\"% Abs/Ins\",\"Votants\",\"% Vot/Ins\",\"% Blancs/Ins\",\"% Blancs/Vot\",\"% Nuls/Ins\",\"% Nuls/Vot\",\"Exprimés\",\"% Exp/Ins\",\"% Exp/Vot\", \"N°Panneau\",\"Sexe\",\"Nom\",\"Prenom\", \"% Voix/Ins\",\"% Voix/Exp\", \"Inscrits\", \"Nuls\"], axis=1)\n",
            "        # Réinitialiser les index du DataFrame des candidats distincts\n",
            "        df_candidats = df_candidats.reset_index(drop=True)\n",
            "\n",
            "        df_candidats[\"codgeo\"] = df_candidats[\"Code du département\"].astype(str).str.zfill(2) + df_candidats[\"Code de la commune\"].astype(str).str.zfill(3)\n",
            "\n",
            "\n",
            "        df_candidats = df_candidats.groupby([\"codgeo\", \"Tendance\"]).agg(\n",
            "        {\n",
            "            \"Voix\": \"sum\",\n",
            "            \"Code du département\": \"first\"\n",
            "        }).reset_index()\n",
            "\n",
            "        df_candidats['Voix'] = pd.to_numeric(df_candidats['Voix'])\n",
            "\n",
            "        df_max_voix  = df_candidats.groupby('codgeo')['Voix'].idxmax()\n",
            "        result = df_candidats.loc[df_max_voix]\n",
            "\n",
            "\n",
            "        # Enregistrer le DataFrame des candidats distincts dans un nouveau fichier CSV\n",
            "        result.to_csv(self.output().path, index=False)\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractLogements(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/logement.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        logement = pd.read_csv(self.file_path, sep=\";\", dtype ='str')\n",
            "\n",
            "        #renomes les colonnes\n",
            "        logement = logement.rename(columns={\"CODGEO\": \"codgeo\", \"P17_RP_VOIT2P\" : \"Au moins deux voitures\", \"P17_MEN\": \"Nb menages\"})\n",
            "        \n",
            "        logement[\"Taux Voitures Menage\"] = logement[\"Au moins deux voitures\"].astype(float) / logement[\"Nb menages\"].astype(float)\n",
            "\n",
            "        colonnes = [\"codgeo\", \"Taux Voitures Menage\"]  \n",
            "\n",
            "        logement = logement[colonnes]\n",
            "\n",
            "        logement['codgeo'] = logement['codgeo'].astype(str)\n",
            "\n",
            "          \n",
            "        logement.to_csv(self.output().path, index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeCommuneLogements(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [ExtractCommunes(file_path=\"./RawData/communes.csv\", file_path1=\"./RawData/partis.csv\"),\n",
            "                ExtractLogements(file_path=\"./RawData/logements.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        logement = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, logement, on='codgeo', how='inner')\n",
            "        merge_data = merge_data.drop_duplicates()\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 40,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "class ExtractRevenus(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/revenus.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        revenus = pd.read_csv(self.file_path, sep=\";\", dtype ='str')\n",
            "        \n",
            "        #renomes les colonnes\n",
            "        revenus = revenus.rename(columns={\"med_disp\" : \"Revenus\"})\n",
            "        \n",
            "        colonnes = [\"codgeo\", \"Revenus\"]\n",
            "\n",
            "        revenus = revenus[colonnes]\n",
            "        \n",
            "        revenus['codgeo'] = revenus['codgeo'].astype(str)\n",
            "                \n",
            "        revenus.to_csv(self.output().path, index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 41,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeRevenusCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [MergeCommuneLogements(file_path=\"./CleanData/2017/communes.csv\", file_path1=\"./CleanData/2017/logement.csv\"), ExtractRevenus(file_path=\"./RawData/revenu_annuel.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        revenus = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, revenus, on='codgeo', how='inner')\n",
            "        \n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 42,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractEmploi(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/emploi.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        emploi = pd.read_csv(self.file_path, sep=\";\", dtype ='str')\n",
            "\n",
            "        #renomes les colonnes\n",
            "        emploi = emploi.rename(columns={\"CODGEO\": \"codgeo\", \"P17_CHOM1564\" : \"Nombre de chômeurs de 15 à 64 ans\", \"P17_ACT1564\": \"Population Active\", \"P17_POP1564\" : \"Population\"})\n",
            "        \n",
            "        emploi[\"Taux Chomage\"] = emploi[\"Nombre de chômeurs de 15 à 64 ans\"].astype(float) / emploi[\"Population Active\"].astype(float) \n",
            "\n",
            "        emploi = emploi.dropna(subset=['Taux Chomage'])\n",
            "\n",
            "        colonnes = [\"codgeo\", \"Nombre de chômeurs de 15 à 64 ans\", \"Population Active\", 'Taux Chomage']\n",
            "        emploi = emploi[colonnes]\n",
            "        \n",
            "        emploi['codgeo'] = emploi['codgeo'].astype(str)\n",
            "\n",
            "        \n",
            "        emploi.to_csv(self.output().path, index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 43,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeEmloiCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [MergeRevenusCommunes(file_path=\"./CleanData/2017/revenus.csv\", file_path1=\"./CleanData/2017/data.csv\"), ExtractEmploi(file_path=\"./RawData/emploi.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        emploi = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, emploi, on='codgeo', how='inner')\n",
            "        merge_data = merge_data.drop_duplicates()\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractPopulation(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/population.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        population = pd.read_csv(self.file_path, sep=\";\", dtype ='str')\n",
            "\n",
            "        #renomes les colonnes\n",
            "        population = population.rename(columns={\"DEPCOM\" :\"codgeo\", \"PTOT\" : \"Population Total\"})\n",
            "        \n",
            "        colonnes = [\"codgeo\", \"Population Total\"]\n",
            "\n",
            "        population = population[colonnes]\n",
            "        \n",
            "        population.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 45,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergePopulationCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [MergeEmloiCommunes(file_path=\"./CleanData/2017/emploi.csv\", file_path1=\"./CleanData/2017/data.csv\"), ExtractPopulation(file_path=\"./RawData/population.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        population = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, population, on='codgeo', how='inner')\n",
            "\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "\n",
            "class ExtractDiplomes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/diplomes.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        # Chargement des dataset\n",
            "        diplomes = pd.read_csv(self.file_path, sep=\";\", dtype ='str')\n",
            "    \n",
            "        #renomes les colonnes\n",
            "        diplomes = diplomes.rename(columns={\"CODGEO\" :\"codgeo\", \"P17_SCOL1824\" : \"Nombre de personnes scolarisées\"})\n",
            "        \n",
            "        diplomes[\"Taux scolarisées\"] = np.where(diplomes[\"P17_POP1824\"].astype(float) != 0,\n",
            "                                       diplomes[\"Nombre de personnes scolarisées\"].astype(float) / diplomes[\"P17_POP1824\"].astype(float),\n",
            "                                       0)\n",
            "        \n",
            "        colonnes = [\"codgeo\", \"Taux scolarisées\"]\n",
            "\n",
            "        diplomes = diplomes[colonnes]\n",
            "        \n",
            "        diplomes.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeDiplomesCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [MergePopulationCommunes(file_path=\"./CleanData/2017/population.csv\", file_path1=\"./CleanData/2017/data.csv\"), ExtractDiplomes(file_path=\"./RawData/diplomes.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        diplomes = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, diplomes, on='codgeo', how='inner')\n",
            "\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "\n",
            "class ExtractEntreprises(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/entreprises.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        # Chargement des dataset\n",
            "        entreprises = pd.read_csv(self.file_path, sep=\";\", dtype ='str')\n",
            "    \n",
            "        entreprises = entreprises.loc[entreprises[\"an\"] == '2017']\n",
            "\n",
            "        #renomes les colonnes\n",
            "        entreprises = entreprises.rename(columns={\"CODGEO\" :\"codgeo\", \"tx_crea_ent\" : \"Taux Creation Entreprise\"})\n",
            "        \n",
            "        entreprises[\"Taux Creation Entreprise\"] = entreprises[\"Taux Creation Entreprise\"].str.replace(',', '.').astype(float)\n",
            "\n",
            "        entreprises[\"Taux Creation Entreprise\"] = entreprises[\"Taux Creation Entreprise\"].fillna(0)\n",
            "\n",
            "        colonnes = [\"codgeo\", \"Taux Creation Entreprise\"]\n",
            "\n",
            "        entreprises = entreprises[colonnes]\n",
            "        \n",
            "        entreprises.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 49,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeEntreprisesCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [MergeDiplomesCommunes(file_path=\"./CleanData/2017/diplomes.csv\", file_path1=\"./CleanData/2017/data.csv\"), ExtractEntreprises(file_path=\"./RawData/entreprises.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        entreprises = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, entreprises, on='codgeo', how='inner')\n",
            "\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Exécuter toutes les tâches"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 50,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ReadAllcommunes(luigi.Task):\n",
            "    def requires(self):\n",
            "        return [MergeEntreprisesCommunes(file_path=\"./CleanData/2017/entreprises.csv\", file_path1=\"./CleanData/2017/data.csv\")]\n",
            "    \n",
            "    def run(self):\n",
            "        print(\"lancement\")\n",
            "\n",
            "    def output(self):\n",
            "        return luigi.LocalTarget('result.txt')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 51,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "DEBUG: Checking if ReadAllcommunes() is complete\n",
                  "DEBUG: Checking if MergeEntreprisesCommunes(file_path=./CleanData/2017/entreprises.csv, file_path1=./CleanData/2017/data.csv) is complete\n",
                  "INFO: Informed scheduler that task   ReadAllcommunes__99914b932b   has status   PENDING\n",
                  "DEBUG: Checking if MergeDiplomesCommunes(file_path=./CleanData/2017/diplomes.csv, file_path1=./CleanData/2017/data.csv) is complete\n",
                  "DEBUG: Checking if ExtractEntreprises(file_path=./RawData/entreprises.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergeEntreprisesCommunes___CleanData_2017___CleanData_2017_5007d70896   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractEntreprises___RawData_entrep_e3f376f420   has status   PENDING\n",
                  "DEBUG: Checking if MergePopulationCommunes(file_path=./CleanData/2017/population.csv, file_path1=./CleanData/2017/data.csv) is complete\n",
                  "DEBUG: Checking if ExtractDiplomes(file_path=./RawData/diplomes.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergeDiplomesCommunes___CleanData_2017___CleanData_2017_35f39063f5   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractDiplomes___RawData_diplom_50127ff020   has status   PENDING\n",
                  "DEBUG: Checking if MergeEmloiCommunes(file_path=./CleanData/2017/emploi.csv, file_path1=./CleanData/2017/data.csv) is complete\n",
                  "DEBUG: Checking if ExtractPopulation(file_path=./RawData/population.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergePopulationCommunes___CleanData_2017___CleanData_2017_f7540f5d9a   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractPopulation___RawData_popula_2b32fec157   has status   PENDING\n",
                  "DEBUG: Checking if MergeRevenusCommunes(file_path=./CleanData/2017/revenus.csv, file_path1=./CleanData/2017/data.csv) is complete\n",
                  "DEBUG: Checking if ExtractEmploi(file_path=./RawData/emploi.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergeEmloiCommunes___CleanData_2017___CleanData_2017_fe2071318a   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractEmploi___RawData_emploi_805348f591   has status   PENDING\n",
                  "DEBUG: Checking if MergeCommuneLogements(file_path=./CleanData/2017/communes.csv, file_path1=./CleanData/2017/logement.csv) is complete\n",
                  "DEBUG: Checking if ExtractRevenus(file_path=./RawData/revenu_annuel.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergeRevenusCommunes___CleanData_2017___CleanData_2017_9481eeed3c   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractRevenus___RawData_revenu_1c4c78a1a4   has status   PENDING\n",
                  "DEBUG: Checking if ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv) is complete\n",
                  "DEBUG: Checking if ExtractLogements(file_path=./RawData/logements.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergeCommuneLogements___CleanData_2017___CleanData_2017_47b355636f   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractLogements___RawData_logeme_08d89daab0   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractCommunes___RawData_commun___RawData_partis_4c969a393a   has status   PENDING\n",
                  "INFO: Done scheduling tasks\n",
                  "INFO: Running Worker with 1 processes\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 14\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ExtractEntreprises(file_path=./RawData/entreprises.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ExtractEntreprises(file_path=./RawData/entreprises.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractEntreprises___RawData_entrep_e3f376f420   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 13\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ExtractDiplomes(file_path=./RawData/diplomes.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ExtractDiplomes(file_path=./RawData/diplomes.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractDiplomes___RawData_diplom_50127ff020   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 12\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ExtractPopulation(file_path=./RawData/population.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ExtractPopulation(file_path=./RawData/population.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractPopulation___RawData_popula_2b32fec157   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 11\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ExtractEmploi(file_path=./RawData/emploi.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ExtractEmploi(file_path=./RawData/emploi.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractEmploi___RawData_emploi_805348f591   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 10\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ExtractRevenus(file_path=./RawData/revenu_annuel.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ExtractRevenus(file_path=./RawData/revenu_annuel.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractRevenus___RawData_revenu_1c4c78a1a4   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 9\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ExtractLogements(file_path=./RawData/logements.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ExtractLogements(file_path=./RawData/logements.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractLogements___RawData_logeme_08d89daab0   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 8\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv)\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>codgeo</th>\n",
                     "      <th>Tendance</th>\n",
                     "      <th>Voix</th>\n",
                     "      <th>Code du département</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>01001</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>280</td>\n",
                     "      <td>1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>01002</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>89</td>\n",
                     "      <td>1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>01004</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>3233</td>\n",
                     "      <td>1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>6</th>\n",
                     "      <td>01005</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>564</td>\n",
                     "      <td>1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>8</th>\n",
                     "      <td>01006</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>37</td>\n",
                     "      <td>1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>71428</th>\n",
                     "      <td>ZZ226</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>82</td>\n",
                     "      <td>ZZ</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>71430</th>\n",
                     "      <td>ZZ227</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>265</td>\n",
                     "      <td>ZZ</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>71432</th>\n",
                     "      <td>ZZ228</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>115</td>\n",
                     "      <td>ZZ</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>71434</th>\n",
                     "      <td>ZZ229</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>3866</td>\n",
                     "      <td>ZZ</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>71436</th>\n",
                     "      <td>ZZ231</td>\n",
                     "      <td>droite</td>\n",
                     "      <td>210</td>\n",
                     "      <td>ZZ</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>35719 rows × 4 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "      codgeo Tendance  Voix Code du département\n",
                     "0      01001   droite   280                   1\n",
                     "2      01002   droite    89                   1\n",
                     "4      01004   droite  3233                   1\n",
                     "6      01005   droite   564                   1\n",
                     "8      01006   droite    37                   1\n",
                     "...      ...      ...   ...                 ...\n",
                     "71428  ZZ226   droite    82                  ZZ\n",
                     "71430  ZZ227   droite   265                  ZZ\n",
                     "71432  ZZ228   droite   115                  ZZ\n",
                     "71434  ZZ229   droite  3866                  ZZ\n",
                     "71436  ZZ231   droite   210                  ZZ\n",
                     "\n",
                     "[35719 rows x 4 columns]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractCommunes___RawData_commun___RawData_partis_4c969a393a   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 7\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   MergeCommuneLogements(file_path=./CleanData/2017/communes.csv, file_path1=./CleanData/2017/logement.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      MergeCommuneLogements(file_path=./CleanData/2017/communes.csv, file_path1=./CleanData/2017/logement.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergeCommuneLogements___CleanData_2017___CleanData_2017_47b355636f   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 6\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   MergeRevenusCommunes(file_path=./CleanData/2017/revenus.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      MergeRevenusCommunes(file_path=./CleanData/2017/revenus.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergeRevenusCommunes___CleanData_2017___CleanData_2017_9481eeed3c   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 5\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   MergeEmloiCommunes(file_path=./CleanData/2017/emploi.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      MergeEmloiCommunes(file_path=./CleanData/2017/emploi.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergeEmloiCommunes___CleanData_2017___CleanData_2017_fe2071318a   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 4\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   MergePopulationCommunes(file_path=./CleanData/2017/population.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      MergePopulationCommunes(file_path=./CleanData/2017/population.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergePopulationCommunes___CleanData_2017___CleanData_2017_f7540f5d9a   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 3\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   MergeDiplomesCommunes(file_path=./CleanData/2017/diplomes.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      MergeDiplomesCommunes(file_path=./CleanData/2017/diplomes.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergeDiplomesCommunes___CleanData_2017___CleanData_2017_35f39063f5   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 2\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   MergeEntreprisesCommunes(file_path=./CleanData/2017/entreprises.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      MergeEntreprisesCommunes(file_path=./CleanData/2017/entreprises.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergeEntreprisesCommunes___CleanData_2017___CleanData_2017_5007d70896   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 1\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) running   ReadAllcommunes()\n",
                  "INFO: [pid 8920] Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) done      ReadAllcommunes()\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ReadAllcommunes__99914b932b   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Done\n",
                  "DEBUG: There are no more tasks to run at this time\n",
                  "INFO: Worker Worker(salt=7173806298, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=8920) was stopped. Shutting down Keep-Alive thread\n",
                  "INFO: \n",
                  "===== Luigi Execution Summary =====\n",
                  "\n",
                  "Scheduled 14 tasks of which:\n",
                  "* 14 ran successfully:\n",
                  "    - 1 ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv)\n",
                  "    - 1 ExtractDiplomes(file_path=./RawData/diplomes.csv)\n",
                  "    - 1 ExtractEmploi(file_path=./RawData/emploi.csv)\n",
                  "    - 1 ExtractEntreprises(file_path=./RawData/entreprises.csv)\n",
                  "    - 1 ExtractLogements(file_path=./RawData/logements.csv)\n",
                  "    ...\n",
                  "\n",
                  "This progress looks :) because there were no failed tasks or missing dependencies\n",
                  "\n",
                  "===== Luigi Execution Summary =====\n",
                  "\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "lancement\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 51,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "config = luigi.configuration.get_config()\n",
            "config.set('core', 'no_lock', 'False')\n",
            "\n",
            "dossier = \"./Cleancommunes/\"\n",
            "Restart = True\n",
            "\n",
            "if Restart is False:\n",
            "    # Parcourir tous les fichiers du dossier\n",
            "    for fichier in os.listdir(dossier):\n",
            "        chemin_fichier = os.path.join(dossier, fichier)\n",
            "        # Supprimer le fichier\n",
            "        os.remove(chemin_fichier)\n",
            "\n",
            "luigi.build([ReadAllcommunes()], local_scheduler=False, no_lock=True)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.0"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
