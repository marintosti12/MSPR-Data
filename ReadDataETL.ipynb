{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 563,
         "metadata": {},
         "outputs": [],
         "source": [
            "import luigi\n",
            "import pandas as pd\n",
            "import os\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Création du dossier pour stocker les données nettoyées"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 564,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Dossier créé avec succès.\n"
               ]
            }
         ],
         "source": [
            "# Vérifiez si le dossier n'existe pas déjà\n",
            "\n",
            "dossier = 'CleanData'\n",
            "\n",
            "if not os.path.exists(dossier):\n",
            "    # Créez le dossier\n",
            "    os.makedirs(dossier, mode=0o777)\n",
            "    os.makedirs(os.path.join(dossier, \"2017\"), mode=0o777)\n",
            "    os.makedirs(os.path.join(dossier, \"2022\"), mode=0o777)\n",
            "    print(\"Dossier créé avec succès.\")\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Extraire les données sur la délinquance"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 565,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/communes.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        communes = pd.read_csv(self.file_path, sep=\",\", low_memory=False)\n",
            "        partis = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        voix_columns = [col for col in communes.columns if col.startswith('Voix')]\n",
            "\n",
            "        # Trouver l'index de la colonne ayant le plus de voix par ligne\n",
            "        index_max_voix = communes[voix_columns].idxmax(axis=1)\n",
            "\n",
            "        # Stock le nom du gagnant dans une colonne\n",
            "        communes['Nom Gagnant'] = communes.apply(lambda row: row['Nom'] if pd.notnull(index_max_voix[row.name]) else None, axis=1)\n",
            "        communes['Prénom Gagnant'] = communes.apply(lambda row: row['Prénom'] if pd.notnull(index_max_voix[row.name]) else None, axis=1)\n",
            "\n",
            "        # Noms de colonnes a garder\n",
            "        colonnes = ['Nom Gagnant', 'Prénom Gagnant', 'Code du département', 'Libellé du département', 'Code de la commune', 'Libellé de la commune']\n",
            "\n",
            "        communes = communes[colonnes]\n",
            "\n",
            "        # Merge du gagnant avec un partis politique\n",
            "        communes = pd.merge(communes, partis, right_on=['Nom', 'Prenom'], left_on=['Nom Gagnant', 'Prénom Gagnant'], how='inner')\n",
            "\n",
            "        communes.to_csv(self.output().path, index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 566,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractRSA(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/rsa.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        rsa = pd.read_csv(self.file_path, sep=\",\")\n",
            "\n",
            "        #Filtre sur l'année 2017\n",
            "        rsa = rsa.query('an == 2017')\n",
            "\n",
            "        #Suppresion des valeurs null\n",
            "        rsa = rsa.dropna()\n",
            "\n",
            "        #renomes les colonnes\n",
            "        rsa = rsa.rename(columns={\"libgeo\": \"Libellé de la commune\", 'alloc_rsa_com' : 'rsa'})\n",
            "        \n",
            "        median = rsa['rsa'].median()\n",
            "        iqr = rsa['rsa'].quantile(0.75) - rsa['rsa'].quantile(0.25)\n",
            "        lower_bound = rsa['rsa'].quantile(0.25) - (1.5 * iqr)\n",
            "        upper_bound = rsa['rsa'].quantile(0.75) + (1.5 * iqr)\n",
            "\n",
            "        rsa = rsa[(rsa['rsa'] >= lower_bound) & (rsa['rsa'] <= upper_bound)]\n",
            "        \n",
            "        rsa = rsa.drop(columns={\"an\"})\n",
            "        \n",
            "        rsa.to_csv(self.output().path, index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 567,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeCommuneRSA(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [ExtractCommunes(file_path=\"./RawData/communes.csv\", file_path1=\"./RawData/partis.csv\"),\n",
            "                ExtractRSA(file_path=\"./RawData/rsa.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        rsa = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, rsa, on='Libellé de la commune', how='inner')\n",
            "\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 568,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractRevenusPauvretes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/revenus_pauvretes.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        revenus = pd.read_csv(self.file_path, sep=\";\")\n",
            "\n",
            "        #renomes les colonnes\n",
            "        revenus = revenus.rename(columns={\"CODGEO\": \"codgeo\", \"NBMENFISC17\" : \"Nombre de ménages fiscaux\", \"NBPERSMENFISC17\" : \"Nombre de personnes dans les ménages fiscaux\", \"MED17\" : \"Niveau de vie\"})\n",
            "        \n",
            "        #Suppresion des valeurs null\n",
            "        revenus = revenus.dropna(subset=[\"Nombre de ménages fiscaux\", \"Nombre de personnes dans les ménages fiscaux\", 'Niveau de vie'])\n",
            "\n",
            "        colonnes = [\"codgeo\", \"Nombre de ménages fiscaux\", \"Nombre de personnes dans les ménages fiscaux\", 'Niveau de vie']\n",
            "        revenus = revenus[colonnes]\n",
            "        \n",
            "        revenus.to_csv(self.output().path, index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 569,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeRevenusCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [MergeCommuneRSA(file_path=\"./CleanData/2017/communes.csv\", file_path1=\"./CleanData/2017/rsa.csv\"), ExtractRevenusPauvretes(file_path=\"./RawData/revenus_pauvretes.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        revenus = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, revenus, on='codgeo', how='inner')\n",
            "\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 570,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ExtractEmploi(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/emploi.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        emploi = pd.read_csv(self.file_path, sep=\";\")\n",
            "\n",
            "        #renomes les colonnes\n",
            "        emploi = emploi.rename(columns={\"CODGEO\": \"codgeo\", \"P17_ACT1564\" : \"Nombre de personnes actives de 15 à 64 ans\", \"P17_CHOM1564\" : \"Nombre de chômeurs de 15 à 64 ans\", \"C17_ACT1564_CS5\" : \"Nombre d'employés actifs de 15 à 64 ans\"})\n",
            "        \n",
            "        #Suppresion des valeurs null\n",
            "        emploi = emploi.dropna(subset=[\"Nombre de personnes actives de 15 à 64 ans\", \"Nombre de chômeurs de 15 à 64 ans\", \"Nombre d'employés actifs de 15 à 64 ans\"])\n",
            "\n",
            "        colonnes = [\"codgeo\", \"Nombre de personnes actives de 15 à 64 ans\", \"Nombre de chômeurs de 15 à 64 ans\", \"Nombre d'employés actifs de 15 à 64 ans\"]\n",
            "        emploi = emploi[colonnes]\n",
            "        \n",
            "        emploi.to_csv(self.output().path, index=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "class MergeEmloiCommunes(luigi.Task):\n",
            "    file_path = luigi.Parameter()\n",
            "    file_path1 = luigi.Parameter()\n",
            "\n",
            "    def requires(self):\n",
            "        return [MergeRevenusCommunes(file_path=\"./CleanData/2017/revenus_pauvretes.csv\", file_path1=\"./CleanData/2017/data.csv\"), ExtractEmploi(file_path=\"./RawData/emploi.csv\")]\n",
            "    \n",
            "    def output(self):\n",
            "        return luigi.LocalTarget(\"./CleanData/2017/data.csv\")\n",
            "\n",
            "\n",
            "    def complete(self):\n",
            "        return self.output().exists()\n",
            "    \n",
            "    def run(self):\n",
            "        \n",
            "        # Chargement des dataset\n",
            "        emploi = pd.read_csv(self.file_path, sep=\",\")\n",
            "        communes = pd.read_csv(self.file_path1, sep=\",\")\n",
            "\n",
            "        merge_data = pd.merge(communes, emploi, on='codgeo', how='inner')\n",
            "\n",
            "        merge_data.to_csv(self.output().path, index=False)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Exécuter toutes les tâches"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 571,
         "metadata": {},
         "outputs": [],
         "source": [
            "class ReadAllcommunes(luigi.Task):\n",
            "    def requires(self):\n",
            "        return [MergeEmloiCommunes(file_path=\"./CleanData/2017/emploi.csv\", file_path1=\"./CleanData/2017/data.csv\")]\n",
            "    \n",
            "    def run(self):\n",
            "        print(\"lancement\")\n",
            "\n",
            "    def output(self):\n",
            "        return luigi.LocalTarget('result.txt')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 572,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "DEBUG: Checking if ReadAllcommunes() is complete\n",
                  "DEBUG: Checking if MergeRevenusCommunes(file_path=./CleanData/2017/revenus_pauvretes.csv, file_path1=./CleanData/2017/data.csv) is complete\n",
                  "DEBUG: Checking if ExtractEmploi(file_path=./RawData/emploi.csv) is complete\n",
                  "INFO: Informed scheduler that task   ReadAllcommunes__99914b932b   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractEmploi___RawData_emploi_805348f591   has status   PENDING\n",
                  "DEBUG: Checking if MergeCommuneRSA(file_path=./CleanData/2017/communes.csv, file_path1=./CleanData/2017/rsa.csv) is complete\n",
                  "DEBUG: Checking if ExtractRevenusPauvretes(file_path=./RawData/revenus_pauvretes.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergeRevenusCommunes___CleanData_2017___CleanData_2017_d6b7462d1b   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractRevenusPauvretes___RawData_revenu_d6412a86d0   has status   PENDING\n",
                  "DEBUG: Checking if ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv) is complete\n",
                  "DEBUG: Checking if ExtractRSA(file_path=./RawData/rsa.csv) is complete\n",
                  "INFO: Informed scheduler that task   MergeCommuneRSA___CleanData_2017___CleanData_2017_568212f751   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractRSA___RawData_rsa_cs_10efe593c8   has status   PENDING\n",
                  "INFO: Informed scheduler that task   ExtractCommunes___RawData_commun___RawData_partis_4c969a393a   has status   PENDING\n",
                  "INFO: Done scheduling tasks\n",
                  "INFO: Running Worker with 1 processes\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 7\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) running   ExtractEmploi(file_path=./RawData/emploi.csv)\n",
                  "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15176\\777256625.py:15: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  emploi = pd.read_csv(self.file_path, sep=\";\")\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) done      ExtractEmploi(file_path=./RawData/emploi.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractEmploi___RawData_emploi_805348f591   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 6\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) running   ExtractRevenusPauvretes(file_path=./RawData/revenus_pauvretes.csv)\n",
                  "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15176\\3091885101.py:15: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  revenus = pd.read_csv(self.file_path, sep=\";\")\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) done      ExtractRevenusPauvretes(file_path=./RawData/revenus_pauvretes.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractRevenusPauvretes___RawData_revenu_d6412a86d0   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 5\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) running   ExtractRSA(file_path=./RawData/rsa.csv)\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) done      ExtractRSA(file_path=./RawData/rsa.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractRSA___RawData_rsa_cs_10efe593c8   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 4\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) running   ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv)\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) done      ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ExtractCommunes___RawData_commun___RawData_partis_4c969a393a   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 3\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) running   MergeCommuneRSA(file_path=./CleanData/2017/communes.csv, file_path1=./CleanData/2017/rsa.csv)\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) done      MergeCommuneRSA(file_path=./CleanData/2017/communes.csv, file_path1=./CleanData/2017/rsa.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergeCommuneRSA___CleanData_2017___CleanData_2017_568212f751   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 2\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) running   MergeRevenusCommunes(file_path=./CleanData/2017/revenus_pauvretes.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) done      MergeRevenusCommunes(file_path=./CleanData/2017/revenus_pauvretes.csv, file_path1=./CleanData/2017/data.csv)\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   MergeRevenusCommunes___CleanData_2017___CleanData_2017_d6b7462d1b   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Pending tasks: 1\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) running   ReadAllcommunes()\n",
                  "INFO: [pid 15176] Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) done      ReadAllcommunes()\n",
                  "DEBUG: 1 running tasks, waiting for next task to finish\n",
                  "INFO: Informed scheduler that task   ReadAllcommunes__99914b932b   has status   DONE\n",
                  "DEBUG: Asking scheduler for work...\n",
                  "DEBUG: Done\n",
                  "DEBUG: There are no more tasks to run at this time\n",
                  "INFO: Worker Worker(salt=3116010434, workers=1, host=DESKTOP-PBH195U, username=Marin, pid=15176) was stopped. Shutting down Keep-Alive thread\n",
                  "INFO: \n",
                  "===== Luigi Execution Summary =====\n",
                  "\n",
                  "Scheduled 7 tasks of which:\n",
                  "* 7 ran successfully:\n",
                  "    - 1 ExtractCommunes(file_path=./RawData/communes.csv, file_path1=./RawData/partis.csv)\n",
                  "    - 1 ExtractEmploi(file_path=./RawData/emploi.csv)\n",
                  "    - 1 ExtractRSA(file_path=./RawData/rsa.csv)\n",
                  "    - 1 ExtractRevenusPauvretes(file_path=./RawData/revenus_pauvretes.csv)\n",
                  "    - 1 MergeCommuneRSA(file_path=./CleanData/2017/communes.csv, file_path1=./CleanData/2017/rsa.csv)\n",
                  "    ...\n",
                  "\n",
                  "This progress looks :) because there were no failed tasks or missing dependencies\n",
                  "\n",
                  "===== Luigi Execution Summary =====\n",
                  "\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "lancement\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 572,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "config = luigi.configuration.get_config()\n",
            "config.set('core', 'no_lock', 'False')\n",
            "\n",
            "dossier = \"./Cleancommunes/\"\n",
            "Restart = True\n",
            "\n",
            "if Restart is False:\n",
            "    # Parcourir tous les fichiers du dossier\n",
            "    for fichier in os.listdir(dossier):\n",
            "        chemin_fichier = os.path.join(dossier, fichier)\n",
            "        # Supprimer le fichier\n",
            "        os.remove(chemin_fichier)\n",
            "\n",
            "luigi.build([ReadAllcommunes()], local_scheduler=False, no_lock=True)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.0"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
